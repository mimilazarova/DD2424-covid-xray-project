{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "playground_colab_mimi.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/DD2424-covid-xray-project/blob/master/playground_colab_mimi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzc7un0tv6uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDks1pN460vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3djAbcsGv6uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/data/trainX1.pickle', 'rb') as f:\n",
        "  X1 = pickle.load(f)\n",
        "with open('/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/data/trainX2.pickle', 'rb') as f:\n",
        "  X2 = pickle.load(f)\n",
        "\n",
        "trainX = np.concatenate((X1, X2))\n",
        "\n",
        "with open('/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/data/testX.pickle', 'rb') as f:\n",
        "  testX = pickle.load(f)\n",
        "with open('/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/data/train_y.pickle', 'rb') as f:\n",
        "  train_y = pickle.load(f)\n",
        "with open('/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/data/test_y.pickle', 'rb') as f:\n",
        "  test_y = pickle.load(f)\n",
        "\n",
        "N = trainX.shape[0]\n",
        "testN = testX.shape[0]\n",
        "\n",
        "trainX = trainX.reshape((N, 224, 224, 1))\n",
        "testX = testX.reshape((testN, 224, 224, 1))\n",
        "\n",
        "# trainX, valX, train_y, val_y = train_test_split(trainX, train_y, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
        "\n",
        "# print(sum(train_y==0)/len(train_y))\n",
        "# print(sum(train_y==1)/len(train_y))\n",
        "# print(sum(train_y==2)/len(train_y))\n",
        "\n",
        "# print(sum(val_y==0)/len(val_y))\n",
        "# print(sum(val_y==1)/len(val_y))\n",
        "# print(sum(val_y==2)/len(val_y))\n",
        "\n",
        "# args = [train_y==0]\n",
        "# X0, vX0, y0, vy0 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# args = [train_y==1]\n",
        "# X1, vX1, y1, vy1 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# args = [train_y==2]\n",
        "# X2, vX2, y2, vy2 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# trainX = np.concatenate((X0, X1, X2))\n",
        "# train_y = np.concatenate((y0, y1, y2))\n",
        "\n",
        "# valX = np.concatenate((vX0, vX1, vX2))\n",
        "# val_y = np.concatenate((vy0, vy1, vy2))\n",
        "\n",
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qagBAmrtLRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = np.argwhere(train_y==1)\n",
        "choices = np.random.choice(ids[:, 0], 10*np.sum(train_y==2), replace=False)\n",
        "\n",
        "X1 = trainX[choices]\n",
        "y1 = train_y[choices]\n",
        "\n",
        "ids = np.argwhere(train_y==0)\n",
        "choices = np.random.choice(ids[:, 0], 10*np.sum(train_y==2), replace=False)\n",
        "\n",
        "X0 = trainX[choices]\n",
        "y0 = train_y[choices]\n",
        "\n",
        "X2 = trainX[train_y==2]\n",
        "y2 = train_y[train_y==2]\n",
        "\n",
        "trainX_balanced = np.concatenate((X0, X1, X2))\n",
        "train_y_balanced = np.concatenate((y0, y1, y2))\n",
        "trainX_balanced.shape\n",
        "\n",
        "trainX, valX, train_y, val_y = train_test_split(trainX_balanced, train_y_balanced, test_size=0.2, random_state=42, shuffle=True, stratify=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGqmliCjuEHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 16\n",
        "init_lr = 2e-4\n",
        "nepoch = 50\n",
        "N = len(train_y)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(init_lr)\n",
        "\n",
        "class_weights = {}\n",
        "# for c in range(3):\n",
        "#   class_weights[c] = 1000/np.sum(train_y==c)\n",
        "#   print(class_weights[c])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)\n",
        "\n",
        "aug = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, \n",
        "                         zoom_range=0.01, horizontal_flip=True,\n",
        "                         vertical_flip=False, fill_mode=\"nearest\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfPriXlxh4OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot-encoded vectors, not sure it we need them, the fitting the models with them did not work for me\n",
        "\n",
        "# trainY = np.zeros((N, 3))\n",
        "# testY = np.zeros((testN, 3))\n",
        "\n",
        "# trainY[np.arange(N), train_y] = 1\n",
        "# testY[np.arange(testN), test_y] = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1EtR2qhtxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = keras.models.Sequential()\n",
        "model2.add(layers.Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape=(224, 224, 1)))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(64, activation='relu'))\n",
        "model2.add(layers.Dropout(0.5))\n",
        "model2.add(layers.Dense(32, activation='relu'))\n",
        "model2.add(layers.Dense(3))\n",
        "\n",
        "class_weights[0] = 1\n",
        "class_weights[1] = 2\n",
        "class_weights[2] = 10\n",
        "\n",
        "model2.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# history2 = model2.fit(trainX, train_y, batch_size = bs, epochs= nepoch,  callbacks=[early_stopping],\n",
        "#                     class_weight=class_weights, validation_data=(valX, val_y))\n",
        "\n",
        "# history2 = model2.fit(trainX_balanced, train_y_balanced, \n",
        "#                       batch_size = bs, epochs= nepoch, \n",
        "#                       callbacks=[early_stopping],\n",
        "#                       validation_data=(valX, val_y))\n",
        "\n",
        "history2 = model2.fit(aug.flow(trainX, train_y, batch_size=bs), \n",
        "                      epochs=nepoch, callbacks=[early_stopping],\n",
        "                      class_weight=class_weights,\n",
        "                      steps_per_epoch = int(N/bs),\n",
        "                      validation_data=(valX, val_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQr2IOnr282b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history2.history['accuracy'], label='accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_y_pred_m = model2.predict(testX)\n",
        "test_y_pred2 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred2, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred2, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjtYQiMGJhcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = keras.models.Sequential()\n",
        "model3.add(layers.Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape=(224, 224, 1)))\n",
        "model3.add(layers.MaxPooling2D((4, 4)))\n",
        "model3.add(layers.Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model3.add(layers.MaxPooling2D((4, 4)))\n",
        "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(layers.Flatten())\n",
        "model3.add(layers.Dense(64, activation='relu'))\n",
        "model3.add(layers.Dense(32, activation='relu'))\n",
        "model3.add(layers.Dense(3))\n",
        "\n",
        "class_weights[0] = 1\n",
        "class_weights[1] = 1\n",
        "class_weights[2] = 4\n",
        "\n",
        "\n",
        "\n",
        "model3.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# history3 = model3.fit(trainX, train_y, \n",
        "#                       batch_size = bs, epochs=nepoch,\n",
        "#                       callbacks=[early_stopping],\n",
        "#                       class_weight=class_weights,\n",
        "#                       validation_data=(valX, val_y))\n",
        "\n",
        "# history3 = model3.fit(trainX_balanced, train_y_balanced, \n",
        "#                       batch_size = bs, epochs=nepoch, \n",
        "#                       callbacks=[early_stopping],\n",
        "#                       validation_data=(valX, val_y))\n",
        "\n",
        "history3 = model3.fit(aug.flow(trainX, train_y, batch_size=bs), \n",
        "                      epochs=nepoch, callbacks=[early_stopping],\n",
        "                      class_weight=class_weights,\n",
        "                      steps_per_epoch = int(N/bs),\n",
        "                      validation_data=(valX, val_y))  \n",
        "\n",
        "plt.plot(history3.history['accuracy'], label='accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_y_pred_m = model3.predict(testX)\n",
        "test_y_pred3 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred3, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred3, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPv0E9ANDX3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_input = layers.Input((224, 224, 1))\n",
        "\n",
        "# X = layers.Conv2D(64, (7, 7), strides=(2, 2), padding = 'same', activation='elu', kernel_initializer='he_normal')(X_input)\n",
        "\n",
        "# X1 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='elu', kernel_initializer='he_normal')(X)\n",
        "\n",
        "# pepx1 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(X1)\n",
        "# pepx1 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx1)\n",
        "# pepx1 = layers.DepthwiseConv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx1)\n",
        "# pepx1 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx1)\n",
        "# pepx1 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx1)\n",
        "\n",
        "# X = layers.Add()([pepx1, X1])\n",
        "\n",
        "# X2 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='elu', kernel_initializer='he_normal')(X)\n",
        "\n",
        "# pepx2 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(X2)\n",
        "# pepx2 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx2)\n",
        "# pepx2 = layers.DepthwiseConv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx2)\n",
        "# pepx2 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx2)\n",
        "# pepx2 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx2)\n",
        "\n",
        "\n",
        "# X = layers.Add()([pepx2, X2])\n",
        "# X3 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='elu', kernel_initializer='he_normal')(X)\n",
        "\n",
        "# pepx3 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(X3)\n",
        "# pepx3 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx3)\n",
        "# pepx3 = layers.DepthwiseConv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx3)\n",
        "# pepx3 = layers.Conv2D(16, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx3)\n",
        "# pepx3 = layers.Conv2D(256, (1, 1), padding='same', activation='elu', kernel_initializer='he_normal')(pepx3)\n",
        "\n",
        "# X = layers.Flatten()(pepx3)\n",
        "# X = layers.Dense(128, activation='elu', kernel_initializer='he_normal')(X)\n",
        "# X = layers.Dense(32, activation='elu', kernel_initializer='he_normal')(X)\n",
        "# X = layers.Dense(3, activation='softmax', kernel_initializer='he_normal')(X)\n",
        "\n",
        "# model5 = keras.models.Model(inputs=X_input, outputs=X)\n",
        "# model5.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o08qhcoHhjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for c in range(3):\n",
        "#   class_weights[c] = np.sum(train_y==(2-c))/N\n",
        "#   print(class_weights[c])\n",
        "\n",
        "\n",
        "# model5.compile(optimizer=optimizer,\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# # history5 = model5.fit(trainX, train_y, batch_size = bs,\n",
        "# #                       epochs=5, callbacks=[early_stopping],\n",
        "# #                       class_weight=class_weights, validation_data=(valX, val_y))  \n",
        "\n",
        "# history5 = model5.fit(aug.flow(trainX, train_y, batch_size = bs),\n",
        "#                       epochs=5, callbacks=[early_stopping],\n",
        "#                       steps_per_epoch = int(N/bs),\n",
        "#                       class_weight=class_weights,\n",
        "#                       validation_data=(valX, val_y))\n",
        "\n",
        "# plt.plot(history5.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history5.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.ylim([0.5, 1])\n",
        "# plt.legend(loc='lower right')\n",
        "\n",
        "# test_y_pred_m = model5.predict(testX)\n",
        "# test_y_pred5 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "# conf_matrix = confusion_matrix(test_y, test_y_pred5, labels=[0, 1, 2])\n",
        "# print(\"Confusion matrix:\")\n",
        "# print(conf_matrix)\n",
        "# print(classification_report(test_y, test_y_pred5, digits=3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OEXi-HqFRzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = train_y.shape[0]\n",
        "testN = test_y.shape[0]\n",
        "for c in range(3):\n",
        "  print(np.sum(test_y==c)/testN)\n",
        "print(\"\\n\")\n",
        "for c in range(3):\n",
        "  print(np.sum(train_y==c)/N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PaHuu7oY4ZLN",
        "colab": {}
      },
      "source": [
        "X_input = layers.Input((224, 224, 1))\n",
        "\n",
        "X = layers.Conv2D(64, (7, 7), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.MaxPool2D((2,2))(X) \n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.MaxPool2D((2,2))(X) \n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "\n",
        "X = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.Dense(3,kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('softmax')(X)\n",
        "\n",
        "model6 = keras.models.Model(inputs=X_input, outputs=X, name='model_6')\n",
        "model6.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JVAuzkyV7hV7",
        "colab": {}
      },
      "source": [
        "class_weights[0] = 1\n",
        "class_weights[1] = 1\n",
        "class_weights[2] = 4\n",
        "\n",
        "\n",
        "model6.compile(optimizer= optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# history6 = model6.fit(trainX, train_y,\n",
        "#                       batch_size=bs, epochs=nepoch,\n",
        "#                       callbacks=[early_stopping],\n",
        "#                       class_weight=class_weights,\n",
        "#                       validation_data=(valX, val_y))  \n",
        "\n",
        "history6 = model6.fit(aug.flow(trainX, train_y, batch_size = bs),\n",
        "                      epochs=nepoch, callbacks=[early_stopping],\n",
        "                      steps_per_epoch = int(N/bs),\n",
        "                      class_weight=class_weights,\n",
        "                      validation_data=(valX, val_y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoHuYijsC9lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history6.history['accuracy'], label='accuracy')\n",
        "plt.plot(history6.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_y_pred_m = model6.predict(testX)\n",
        "test_y_pred6 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred6, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred6, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n1VAgxTPe7py",
        "colab": {}
      },
      "source": [
        "X_input = layers.Input((224, 224, 1))\n",
        "\n",
        "X = layers.Conv2D(64, (7, 7), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.MaxPool2D((2,2))(X) \n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.MaxPool2D((2,2))(X) \n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X3 = layers.Conv2D(1024, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "b3 = layers.MaxPool2D((2,2))(X) \n",
        "b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "b3 = layers.Activation('relu')(b3)\n",
        "b3 = layers.Conv2D(1024, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "X = layers.Add()([X3, b3])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.Dense(3,kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('softmax')(X)\n",
        "\n",
        "model7 = keras.models.Model(inputs=X_input, outputs=X, name='model_7')\n",
        "model7.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HDdMTqgIf2jo",
        "colab": {}
      },
      "source": [
        "class_weights = {}\n",
        "for c in range(3):\n",
        "  class_weights[c] = 1000/np.sum(train_y==c)\n",
        "  print(class_weights[c])\n",
        "# class_weights[0] = 1\n",
        "# class_weights[1] = 2\n",
        "# class_weights[2] = 8\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)\n",
        "\n",
        "\n",
        "model7.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# history7 = model7.fit(trainX, train_y,\n",
        "#                       batch_size=bs, epochs=nepoch,\n",
        "#                       callbacks=[early_stopping],\n",
        "#                       class_weight=class_weights,\n",
        "#                       validation_data=(valX, val_y))  \n",
        "\n",
        "history7 = model7.fit(aug.flow(trainX, train_y, batch_size = bs),\n",
        "                      epochs=nepoch, callbacks=[early_stopping],\n",
        "                      steps_per_epoch = int(N/bs),\n",
        "                      class_weight=class_weights,\n",
        "                      validation_data=(valX, val_y))\n",
        "\n",
        "\n",
        "plt.plot(history7.history['accuracy'], label='accuracy')\n",
        "plt.plot(history7.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_y_pred_m = model7.predict(testX)\n",
        "test_y_pred7 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred7, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred7, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vdfV_Cqjuu36",
        "colab": {}
      },
      "source": [
        "X_input = layers.Input((224, 224, 1))\n",
        "\n",
        "X = layers.Conv2D(64, (7, 7), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.MaxPool2D((2,2))(X) \n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.MaxPool2D((2,2))(X) \n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X3 = layers.Conv2D(1024, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "b3 = layers.MaxPool2D((2,2))(X) \n",
        "b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "b3 = layers.Activation('relu')(b3)\n",
        "b3 = layers.Conv2D(1024, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "X = layers.Add()([X3, b3])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X3 = layers.Conv2D(1024, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "b3 = layers.Activation('relu')(b3)\n",
        "b3 = layers.Conv2D(1024, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "X = layers.Add()([X3, b3])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.Dense(3,kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('softmax')(X)\n",
        "\n",
        "model8 = keras.models.Model(inputs=X_input, outputs=X, name='model_8')\n",
        "#model8.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJgVNsU3u0zI",
        "colab": {}
      },
      "source": [
        "class_weights[0] = 1\n",
        "class_weights[1] = 1\n",
        "class_weights[2] = 10\n",
        "\n",
        "# metrics = [keras.metrics.TopKCategoricalAccuracy(), keras.metrics.Accuracy()]\n",
        "\n",
        "dirname = \"/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/\"\n",
        "\n",
        "filename = \"model8-undersampling-weights-augmentation.hdf5\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(dirname, filename),  \n",
        "                                        monitor=\"val_accuracy\",\n",
        "                                        safe_best_only = True,\n",
        "                                        verbose=1)\n",
        "\n",
        "model8.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# history8 = model8.fit(trainX, train_y, batch_size=8,\n",
        "#                       epochs=25, callbacks=[early_stopping],\n",
        "#                       class_weight=class_weights, validation_data=(valX, val_y))\n",
        "  \n",
        "# history8 = model8.fit(trainX_balanced, train_y_balanced, \n",
        "#                       batch_size = 8, epochs=25, \n",
        "#                       callbacks=[early_stopping],\n",
        "#                       validation_data=(valX, val_y))\n",
        "\n",
        "history8 = model8.fit(aug.flow(trainX, train_y, batch_size = bs),\n",
        "                      epochs=nepoch, callbacks=[early_stopping, checkpoint],\n",
        "                      steps_per_epoch = int(N/bs),\n",
        "                      class_weight=class_weights,\n",
        "                      validation_data=(valX, val_y))\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history8.history['accuracy'], label='accuracy')\n",
        "plt.plot(history8.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "\n",
        "val_y_pred_m = model8.predict(valX)\n",
        "val_y_pred8 = np.argmax(val_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(val_y, val_y_pred8, labels=[0, 1, 2])\n",
        "print(\"Validation set\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(val_y, val_y_pred8, digits=3))\n",
        "\n",
        "test_y_pred_m = model8.predict(testX)\n",
        "test_y_pred8 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred8, labels=[0, 1, 2])\n",
        "print(\"Test set\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred8, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIWb1gstVr65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dirname = \"/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/\"\n",
        "filename = \"model8-3-augmentation-16-0.78.hdf5\"\n",
        "m = keras.models.load_model(os.path.join(dirname, filename))\n",
        "\n",
        "val_y_pred_m = m.predict(valX)\n",
        "val_y_pred8 = np.argmax(val_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(val_y, val_y_pred8, labels=[0, 1, 2])\n",
        "print(\"Validation set\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(val_y, val_y_pred8, digits=3))\n",
        "\n",
        "test_y_pred_m = m.predict(testX)\n",
        "test_y_pred8 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred8, labels=[0, 1, 2])\n",
        "print(\"Test set\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred8, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRzSSGVGlG5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filename = \"/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/model8.h5\"\n",
        "# model8.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7st40zonXrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/drive/My Drive/KTH/Year 1/DD2424 Deep Learning/DD2424_Project/model8-16-0.91.hdf5\"\n",
        "loaded = keras.models.load_model(filename)\n",
        "test_y_pred_m = loaded.predict(testX)\n",
        "test_y_pred8 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred8, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)\n",
        "print(classification_report(test_y, test_y_pred8, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}