{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "playground_diego.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/DD2424-covid-xray-project/blob/master/playground_diego.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzc7un0tv6uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from tensorflow.python.keras.applications import ResNet50\n",
        "# from tensorflow.python.keras.models import Sequential\n",
        "# from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDks1pN460vn",
        "colab_type": "code",
        "outputId": "2432595f-747f-45a9-ffcf-53fe7b7948af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3djAbcsGv6uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/DD2424_Project/data/trainX1.pickle', 'rb') as f:\n",
        "  X1 = pickle.load(f)\n",
        "with open('/content/drive/My Drive/DD2424_Project/data/trainX2.pickle', 'rb') as f:\n",
        "  X2 = pickle.load(f)\n",
        "\n",
        "trainX = np.concatenate((X1, X2))\n",
        "\n",
        "with open('/content/drive/My Drive/DD2424_Project/data/testX.pickle', 'rb') as f:\n",
        "  testX = pickle.load(f)\n",
        "with open('/content/drive/My Drive/DD2424_Project/data/train_y.pickle', 'rb') as f:\n",
        "  train_y = pickle.load(f)\n",
        "with open('/content/drive/My Drive/DD2424_Project/data/test_y.pickle', 'rb') as f:\n",
        "  test_y = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTEV-LT2dIEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = trainX.shape[0]\n",
        "testN = testX.shape[0]\n",
        "\n",
        "trainX = trainX.reshape((N, 224, 224, 1))\n",
        "testX = testX.reshape((testN, 224, 224, 1))\n",
        "\n",
        "trainX, valX, train_y, val_y = train_test_split(trainX, train_y, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
        "\n",
        "# args = [train_y==0]\n",
        "# X0, vX0, y0, vy0 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# args = [train_y==1]\n",
        "# X1, vX1, y1, vy1 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# args = [train_y==2]\n",
        "# X2, vX2, y2, vy2 = train_test_split(trainX[args], train_y[args],  test_size=0.1, random_state=42) \n",
        "\n",
        "# trainX = np.concatenate((X0, X1, X2))\n",
        "# train_y = np.concatenate((y0, y1, y2))\n",
        "\n",
        "# valX = np.concatenate((vX0, vX1, vX2))\n",
        "# val_y = np.concatenate((vy0, vy1, vy2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug9S4VJjgQck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainX2 = np.copy(trainX)\n",
        "# valX2 = np.copy(valX)\n",
        "# train_y2 = np.copy(train_y)\n",
        "# val_y2 = np.copy(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIBOuIX3NAOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6ad755c-338e-48d5-80ee-13579919e750"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10855, 224, 224, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp3H9qH-ZcOT",
        "colab_type": "code",
        "outputId": "838aedc8-5183-4501-b139-c20be3856a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10855,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlZnEjd9ZeBm",
        "colab_type": "code",
        "outputId": "143c3d1b-eae1-4460-eee9-51bc381006c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valX.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2714, 224, 224, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYv6oLBbZfLP",
        "colab_type": "code",
        "outputId": "3c927e0d-3ec7-45d5-8dd6-5cdef9cb44f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2714,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5XmWIUXZnnf",
        "colab_type": "code",
        "outputId": "c6195a14-48cf-4ca8-d033-89abede567fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "num_classes = 3\n",
        "class_weights = {}\n",
        "for c in range(3):\n",
        "  class_weights[c] = 1000/np.sum(train_y==c)\n",
        "  print(class_weights[c])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15654351909830932\n",
            "0.2296738631143776\n",
            "8.849557522123893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z76ICIZ-XxB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = trainX.shape[0]\n",
        "valN = valX.shape[0]\n",
        "testN = testX.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr78uvnDv6uZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "289456c0-76b1-447b-e324-768ff6ef3228"
      },
      "source": [
        "trainX = trainX.reshape((N, 224, 224, 1))\n",
        "trainX = np.repeat(trainX[0:2000,:,:,:], 3, axis=-1)\n",
        "\n",
        "trainX.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ade3B8wi8-99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a791feb-3ec3-41c0-f99e-bf20c1520b75"
      },
      "source": [
        "testX.shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB8XwFJUtNpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2be1ddbb-14cd-49a5-f492-ec1f70151a44"
      },
      "source": [
        "valX = valX.reshape((valN, 224, 224, 1))\n",
        "valX = np.repeat(valX, 3, axis=-1)\n",
        "valX.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2714, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLszihz5v6ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f2a5b144-5206-43cf-b1c4-bc814f7fea68"
      },
      "source": [
        "#Build Model\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "model1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model. It is already trained\n",
        "model1.layers[0].trainable = False\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 6147      \n",
            "=================================================================\n",
            "Total params: 23,593,859\n",
            "Trainable params: 6,147\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiLPBL79v6uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile Model\n",
        "model1.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9HEH7IlOI9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f6588611-1509-4ba2-f516-690b2de57309"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Specify the values for all arguments to data_generator_with_aug.\n",
        "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                              horizontal_flip = True,\n",
        "                                              width_shift_range = 0.1,\n",
        "                                              height_shift_range = 0.1)\n",
        "\n",
        "# datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "# datagen.fit(trainX)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "# model1.fit(datagen.flow(trainX, train_y, batch_size=32),\n",
        "                    # steps_per_epoch=len(trainX) / 32, epochs=5)\n",
        "\n",
        "\n",
        "#Fit model\n",
        "history1 = model1.fit(data_generator.flow(trainX, train_y[0:2000], batch_size=16),\n",
        "                      epochs=20, steps_per_epoch = int(N/16),\n",
        "                      validation_data=(valX, val_y))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2f557cc23468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m history1 = model1.fit(data_generator.flow(trainX, train_y[0:2000], batch_size=16),\n\u001b[0m\u001b[1;32m     23\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       validation_data=(valX, val_y))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIhriiNu9zh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = keras.models.Sequential()\n",
        "model1.add(Conv2D(64, (5, 5), padding = 'same', activation='relu', input_shape=(224, 224, 1)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(MaxPooling2D((4, 4)))\n",
        "model1.add(Conv2D(64, (5, 5), padding = 'same', activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(MaxPooling2D((4, 4)))\n",
        "model1.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dense(10, activation='relu'))\n",
        "model1.add(Dense(3))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN82VtrV908B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history1 = model1.fit(trainX, train_y, epochs=5, \n",
        "                    validation_data=(testX, test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XXu8w-xvb18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', input_shape=(224,224,1)))\n",
        "  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "    \n",
        "  model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu', strides=1, padding='same'))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.5))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.5))\n",
        "  model.add(Dense(3))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWj9Vh1ovK7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model1 = make_model()\n",
        "model1.summary()\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam (lr=0.001)\n",
        "\n",
        "model1.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "\n",
        "history1 = model1.fit(trainX, train_y, epochs=5, \n",
        "                    # validation_data=(testX, test_y), callbacks=[reduce_lr])\n",
        "                    validation_data=(testX, test_y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0DPp_IJ6jaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history1.history['accuracy'], label='accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_y_pred_m = model1.predict(testX)\n",
        "test_y_pred1 = np.argmax(test_y_pred_m, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, test_y_pred1, labels=[0, 1, 2])\n",
        "print(\"Confusion matrix:\")\n",
        "print(conf_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0irOaGL1zUR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(test_y_pred_m, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}