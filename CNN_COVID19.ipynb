{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/DD2424-covid-xray-project/blob/master/CNN_COVID19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQi8HIgYYxQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouH43lxmY4gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LYPHMsCZHwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training data\n",
        "with open('/content/drive/My Drive/data/trainX1.pickle', 'rb') as f:\n",
        "  X1 = pickle.load(f)\n",
        "with open('/content/drive/My Drive/data/trainX2.pickle', 'rb') as f:\n",
        "  X2 = pickle.load(f)\n",
        "with open('/content/drive/My Drive/data/train_y.pickle', 'rb') as f:\n",
        "  train_y = pickle.load(f)\n",
        "\n",
        "trainX = np.concatenate((X1, X2))\n",
        "del X1\n",
        "del X2\n",
        "\n",
        "# Load test data\n",
        "with open('/content/drive/My Drive/data/testX.pickle', 'rb') as f:\n",
        "  testX = pickle.load(f)\n",
        "with open('/content/drive/My Drive/data/test_y.pickle', 'rb') as f:\n",
        "  test_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LzvS68PbtVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add axis for n_channels = 1 (Gray-scale images)\n",
        "trainN = trainX.shape[0]\n",
        "testN = testX.shape[0]\n",
        "trainX = trainX.reshape((trainN, 224, 224, 1))\n",
        "testX = testX.reshape((testN, 224, 224, 1))\n",
        "\n",
        "# Class balancing\n",
        "ids = np.argwhere(train_y==1)\n",
        "choices = np.random.choice(ids[:, 0], 10*np.sum(train_y==2), replace=False)\n",
        "X1 = trainX[choices]\n",
        "y1 = train_y[choices]\n",
        "\n",
        "ids = np.argwhere(train_y==0)\n",
        "choices = np.random.choice(ids[:, 0], 10*np.sum(train_y==2), replace=False)\n",
        "X0 = trainX[choices]\n",
        "y0 = train_y[choices]\n",
        "X2 = trainX[train_y==2]\n",
        "y2 = train_y[train_y==2]\n",
        "\n",
        "trainX_balanced = np.concatenate((X0, X1, X2))\n",
        "train_y_balanced = np.concatenate((y0, y1, y2))\n",
        "trainX_balanced.shape\n",
        "\n",
        "# Split data for training and validatiom\n",
        "trainX, valX, train_y, val_y = train_test_split(trainX_balanced, train_y_balanced, test_size=0.2, random_state=42, shuffle=True, stratify=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOac21J4csH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Built CNN model\n",
        "X_input = layers.Input((224, 224, 1))\n",
        "\n",
        "X = layers.Conv2D(64, (7, 7), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.MaxPool2D((2,2))(X) \n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "b1 = layers.Activation('relu')(b1)\n",
        "b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "\n",
        "X = layers.Add()([X1, b1])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.MaxPool2D((2,2))(X) \n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X2 = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "b2 = layers.Activation('relu')(b2)\n",
        "b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "X = layers.Add()([X2, b2])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X3 = layers.Conv2D(1024, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "b3 = layers.MaxPool2D((2,2))(X) \n",
        "b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "b3 = layers.Activation('relu')(b3)\n",
        "b3 = layers.Conv2D(1024, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "X = layers.Add()([X3, b3])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X3 = layers.Conv2D(1024, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "b3 = layers.Activation('relu')(b3)\n",
        "b3 = layers.Conv2D(1024, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "X = layers.Add()([X3, b3])\n",
        "X = layers.Activation('relu')(X)\n",
        "\n",
        "X = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.Dense(3,kernel_initializer='he_uniform')(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation('softmax')(X)\n",
        "\n",
        "model = keras.models.Model(inputs=X_input, outputs=X, name='model_8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeFTVajwcAtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 2e-4 \n",
        "epochs = 50\n",
        "\n",
        "# Class weights for class balancing\n",
        "class_weights = {}\n",
        "for c in range(3):\n",
        "  class_weights[c] = 1000 / np.sum(train_y==c)\n",
        "\n",
        "class_weights[0] = 1\n",
        "class_weights[1] = 1\n",
        "class_weights[2] = 10\n",
        "\n",
        "# Set optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Data augmentation\n",
        "aug = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, \n",
        "                          width_shift_range=0.1, height_shift_range=0.1, \n",
        "                          shear_range=0.2,  zoom_range=0.01, \n",
        "                          horizontal_flip=True, vertical_flip=False, \n",
        "                          fill_mode=\"nearest\")\n",
        "\n",
        "# Callbacks, early stopping and best model restoration\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                          verbose=1, patience=10, mode='max', \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "dirname = \"/content/drive/My Drive/\"\n",
        "filename = \"model8-undersampling-weights-augmentation.hdf5\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "                          filepath=os.path.join(dirname, filename),  \n",
        "                          monitor=\"val_accuracy\", safe_best_only = True,\n",
        "                          verbose=1)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(aug.flow(trainX, train_y, batch_size=batch_size),\n",
        "                          epochs=epochs, callbacks=[early_stopping, checkpoint],\n",
        "                          steps_per_epoch = int(len(train_y) / batch_size),\n",
        "                          class_weight=class_weights,\n",
        "                          validation_data=(valX, val_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hwemhzZq2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot results\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW8_Kv1gZg1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict validation data\n",
        "val_y_pred = np.argmax(model.predict(valX), axis=1)\n",
        "print(\"Validation set prediction:\")\n",
        "print(confusion_matrix(val_y, val_y_pred, labels=[0, 1, 2]))\n",
        "print(classification_report(val_y, val_y_pred, digits=3))\n",
        "\n",
        "# Predict test data\n",
        "test_y_pred = np.argmax(model.predict(testX), axis=1)\n",
        "print(\"Test set prediction:\")\n",
        "print(confusion_matrix(test_y, test_y_pred, labels=[0, 1, 2]))\n",
        "print(classification_report(test_y, test_y_pred, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}